1
---
#first export aws access key to .bashrc file
https://computingforgeeks.com/how-to-install-terraform-on-ubuntu/
$ export AWS_ACCESS_KEY_ID=(your access key id)
$ export AWS_SECRET_ACCESS_KEY=(your secret access key)
if install awscli and login already it will be in .aws dir
##terraform init create configuration and provider plugins
where you store main.tf file
terraform init 
Initializing the backend...
Initializing provider plugins...
#to provision create main.tf , terraform init, terraform plan, terraform apply
c2: one-server ec2 run in the region specified
terraform {
  required_version = ">= 1.0.0, < 2.0.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

provider "aws" {
  region = "us-east-2"
}

resource "aws_instance" "example" {
  ami           = "ami-0fb653ca2d3203ac1"
  instance_type = "t2.micro"

  tags = {
    Name = "terraform-example"
  }
}
---
#prt: use user_data to configure script run
c2: one-web run normally
 user_data = <<-EOF
              #!/bin/bash
              echo "Hello, World" > index.html
              nohup busybox httpd -f -p 8080 &
              EOF

  user_data_replace_on_change = true

#terraform use implicit dependencies, parses these dependencies, builds a dependency graph from them
terraform graph
#prt: terraform use variable to use in and out of the code
c2: 
variable "server_port" {
  description = "The port the server will use for HTTP requests"
  type        = number
  default     = 8080
}
---
#use aws_autoscaling_group with aws_launch_configuration to provide autoscaling
chap 2 web_cluster
resource "aws_autoscaling_group" "example" {
launch_configuration = aws_launch_configuration.example.name
min_size = 2
max_size = 10
tag {
key = "Name"
value = "terraform-asg-example"
propagate_at_launch = true
}
}
#use lifecycle create_before_destroy when you replace an instance that is a dependency
chap 2 web-cluster
in launch configuration 
lifecycle {
create_before_destroy = true
}
#data source add api data and make it available in the rest of the code, other source call it's attributes
data "<PROVIDER>_<TYPE>" "<NAME>" {
[CONFIG ...]
}
data "aws_vpc" "default" {
default = true
}
--
#terraform save state and diff to apply change
in terraform apply
#should not save state in version control but best in cloud storage
IaC/terraform/code/terraform/03-terraform-state/file-layout-example/global/s3 chap 3/global
resource "aws_s3_bucket" "terraform_state" {

  bucket = var.bucket_name
}
#terraform use workspaces to store multiple seperate states
Terraform workspaces allow you to store your Terraform state in multiple,
separate, named workspaces. Terraform starts with a single workspace called
“default,” and if you never explicitly specify a workspace, the default workspace
is the one you’ll use the entire time. To create a new workspace or switch
between workspaces, you use the terraform workspace commands.
---
2
---
#shoud use different folder for: stage or prod, components(web,db) and use seperate backend storage (s3)
.
├── global
│   └── s3
│       ├── README.md
│       ├── main.tf
│       ├── outputs.tf
│       └── variables.tf
└── stage
    ├── data-stores
    │   └── mysql
    │       ├── README.md
    │       ├── main.tf
    │       ├── outputs.tf
    │       └── variables.tf
    └── services
        └── webserver-cluster
            ├── README.md
            ├── main.tf
            ├── outputs.tf
            ├── user-data.sh
            └── variables.tf

#could seperate .tf file because terraform just read .tf file
#terraform_remote_state is terraform data source that take output of other resource state
data.terraform_remote_state.<NAME>.outputs.<ATTRIBUTE>
echo "${data.terraform_remote_state.db.outputs.address}" >> index.html
---
#file reads a file from disk and returns its literal contents without any template interpretation.
file("user-data.sh")
./code/terraform/03-terraform-state/file-layout-example/stage/services/webserver-cluster/user-data.sh
#templatefile is a function read file (bash script) and use variable to create template
templatefile(path, vars)
For Terraform 0.12 and later, the template_file data source has been superseded by the templatefile function,
#rendered attribute: result of template
user_data = data.template_file.user_data.rendered
---
#Modules are reusable Terraform configurations (use in many enviroments stage/prod)
#could define variable parameters in module and input it in main.tf, also could output from module
#local variable is defined in module and can not be inputed ( like http_port)
---
#use path. reference to read module file location
#use seperate resources instead of inline blocks allow you to add custome config latter to that resource
#best to store module and live to seperate repos in github
3
---
#use tag to version the module code in git, change it for prod when it's ready 
#prt: c2: install terraform and setup aws
#prt: c2: provision web server cluster
---
#very time you run Terraform, it records information about what infrastructure it
created in a Terraform state file. By default, when you run Terraform in the
folder /foo/bar, Terraform creates the file /foo/bar/terraform.tfstate. This file
contains a custom JSON format that records a mapping from the Terraform
resources in your configuration files to the representation of those resources in
the real world. 
#prt: provision s3 file layout with dynamo db 03-terraform-state/file-layout-example
#prt: The only solution available as of May 2019 is to take advantage of partial
configuration, in which you omit certain parameters from the backend
configuration in your Terraform code and instead pass those in via -backendconfig command-line arguments when calling terraform init.
---
#When you first
start using Terraform, you might be tempted to define all of your infrastructure
in a single Terraform file or a single set of Terraform files in one folder. The
problem with this approach is that all of your Terraform state is now stored in a
single file, too, and a mistake anywhere could break everything.
#prt: c3 use seperate workspaces
#prt: c3 provision web server cluster with seperate layout
---
#terraform_remote_state. You can use this data source to fetch the
Terraform state file stored by another set of Terraform configurations in a
completely read-only manner.
#One option for handling secrets is to use a Terraform data source to read the
secrets from a secret store. For example, you can store secrets, such as database
passwords, in AWS Secrets Manager, which is a managed service AWS offers
specifically for storing sensitive data. You could use the AWS Secrets Manager
UI to store the secret and then read the secret back out in your Terraform code
using the aws_secretsmanager_secret_version data source:
#The second option for handling secrets is to manage them completely outside of
Terraform (e.g., in a password manager such as 1Password, LastPass, or OS X
Keychain) and to pass the secret into Terraform via an environment variable. To
do that, declare a variable called db_password in stage/datastores/mysql/variables.tf:
4,
---
#All of the database’s output variables are stored in the state file and you can read
them from the terraform_remote_state data source using an attribute
reference of the form:
data.terraform_remote_state.<NAME>.outputs.<ATTRIBUTE>i
#Terraform includes a number of built-in functions that you can execute using an
expression of the form:
function_name(...)
#When the User Data script was embedded in the Terraform code,
you used Terraform references and interpolation to fill in these values. This does
not work with the file function. However, it does work if you use a
template_file data source.
---
#The final step is to update the user_data parameter of the
aws_launch_configuration resource to point to the rendered output attribute
of the template_file data source:
#With Terraform, you can put your code inside of a Terraform module and reuse
that module in multiple places throughout your code. Instead of having the same
code copied and pasted in the staging and production environments, you’ll be
able to have both environments reuse code from the same module
#, create a new top-level
folder called modules and move all of the files from stage/services/webservercluster to modules/services/webserver-cluster.
---
#You can now make use of this module in the staging environment. Here’s the
syntax for using a module:
module "<NAME>" {
source = "<SOURCE>"
[CONFIG ...]
}
where NAME is an identifier you can use throughout the Terraform code to refer to
this module (e.g., web-service), SOURCE is the path where the module code can
be found (e.g., modules/services/webserver-cluster), and CONFIG consists of one
or more arguments that are specific to that module
#In Terraform, modules can have input parameters, too. To define them, you use a
mechanism you’re already familiar with: input variables. Open up
modules/services/webserver-cluster/variables.tf and add three new input
variables
#Local values allow you to assign a name to any Terraform expression, and to use
that name throughout the module. These names are only visible within the
module, so they will have no impact on other modules, and you can’t overridethese values from outside of the module.
---
#In Terraform, a module can also return values. Again, you do this using a
mechanism you already know: output variables. You can add the ASG name as
an output variable in /modules/services/webserver-cluster/outputs.tf as follows:
#prt: use module to build web-clusters 
#you can use an expression known as a path reference, which
is of the form path.<TYPE>. Terraform supports the following types of path
references:
path.module
Returns the filesystem path of the module where the expression is defined.
path.root
Returns the filesystem path of the root module.
path.cwd
5,
---
#The easiest way to create a
versioned module is to put the code for the module in a separate Git repository
and to set the source parameter to that repository’s URL. That means your
Terraform code will be spread out across (at least) two repositories:
#prt: c5 use count parameter to provide 3 IAM users live/global/iam/main.tf:
#every Terraform resource
has a meta-parameter you can use called count. count is Terraform’s oldest,
simplest, and most limited iteration construct: all it does is define how many
copies of the resource to create
---
#prt: user count index and seperate variables for naming live/global/iam/variables.tf
#count cons: inline blocks and delete
#The for_each expression allows you to loop over lists, sets, and maps to create
either (a) multiple copies of an entire resource, or (b) multiple copies of an inline
block within a resource.
---
#prt: user foreach expression to create multi users and delete
#prt: c5 Let’s now turn our attention to another advantage of for_each: it’s ability to
create multiple inline blocks within a resource. For example, you can use
for_each to dynamically generate tag inline blocks for the ASG in the
webserver-cluster module.
#prt: Terraform offers similar functionality in the form of a for expression (not to be
confused with the for_each expression you saw in the previous section). The
basic syntax of a for expression is:
[for <ITEM> in <LIST> : <OUTPUT>] 
---
#Terraform’s for expression also allows you to loop over a map using the
following syntax:
[for <KEY>, <VALUE> in <MAP> : <OUTPUT>]
#String directives allow you to use control statements (e.g., for-loops and ifstatements) within strings using a syntax similar to string interpolations, but
instead of a dollar sign and curly braces (${…}), you use a percent sign and curly
braces (%{…}).
#prt: c5 conditionals using count and contidtional expression
6,
---
#prt: The goal is to attach one of these IAM policies to neo, based on the value of a
new input variable called give_neo_cloudwatch_full_
#prt: The question is, how can you allow the user of the webserver-cluster module
to pick from one of these User Data scripts?
#prt: Conditionals with for_each and for Expressions
---
#prt: %{ if <CONDITION> }<TRUEVAL>%{ endif }
where CONDITION is any expression that evaluates to a boolean and TRUEVAL is
the expression to render if CONDITION evaluates to true. You can optionally
include an else clause as follows:
%{ if <CONDITION> }<TRUEVAL>%{ else }<FALSEVAL>%{ endif }
#prt: Zero-Downtime Deployment
#Terraform requires that it can compute count and for_each during the plan
phase, before any resources are created or modified. This means that count and
for_each can reference hardcoded values, variables, data sources, and even lists
of resources (so long as the length of the list can be determined during plan), but
not computed resource outputs.
---
#Unfortunately, as of Terraform 0.12.6, using count or for_each on module is
not supported. According to the Terraform 0.12 release notes, this is something
HashiCorp plans to add in the future, so depending on when you’re reading this
book, it might already be available. Check the Terraform CHANGELOG to find
out.
#Using create_before_destroy with an ASG is a great technique for zerodowntime deployment, but there is one limitation: it doesn’t work with auto
scaling policies. Or, to be more accurate, it resets your ASG size back to its
min_size after each deployment, which can be a problem if you had used autoscaling policies to increase the number of running servers.
#prt: above issue workaround
---
#If you have existing infrastructure, use the import command
# common programming practice is refactoring, in which you restructure the
internal details of an existing piece of code without changing its external
behavior.
#chage state: terraform state mv command, which has the following syntax:
terraform state mv <ORIGINAL_REFERENCE> <NEW_REFERENCE>
$ terraform state mv \
aws_security_group.instance \
aws_security_group.cluster_instance
